{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SoVnzS8UHDs"
      },
      "source": [
        "# Programming Lab 5 - Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9fnVvt7UK9x"
      },
      "source": [
        "***\n",
        "##### CS 434 - Data Mining and Machine Learning\n",
        "##### Oregon State University-Cascades\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bkzIVhj6FGe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Austin Martin's Lab 5 submission\n"
          ]
        }
      ],
      "source": [
        "name = \"Austin Martin\"   # <== fill in\n",
        "assert name != \"\"\n",
        "print(name+'\\'s Lab 5 submission')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu2HDJf6UObF"
      },
      "source": [
        "***\n",
        "# Load packages \n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZTf_JwKUQp1"
      },
      "source": [
        "Any additional packages you need for this lab should be added here.\n",
        "\n",
        "**DO NOT** import packages anywhere else!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yk4gw-zCxuBa"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats.stats import pearsonr\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euBP3zbtxwzp"
      },
      "source": [
        "***\n",
        "# Objective\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OePCST_ex431"
      },
      "source": [
        "This is an open-ended lab in which you will explore TensorFlow on a problem of your choosing.\n",
        "\n",
        "1.  Pick a dataset\n",
        "2.  Build a tensorflow deep learning model\n",
        "3.  Train and test your model\n",
        "4.  Analyze your results\n",
        "5.  Write a report\n",
        "\n",
        "> **Submission**: run the entire notebook before submission.  I will **not** re-run it to grade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjOFDAXoUVCv"
      },
      "source": [
        "***\n",
        "# Data\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SgoQShs6JVF"
      },
      "source": [
        "##### Protips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsiRAOLLEdeV"
      },
      "source": [
        "A good strategy is to read several related articles on a topic (e.g., image classification with CNN) and **interpolate** an approach that combines aspects from each source. Then, apply this approach on on an entirely **different dataset** not used in the articles. \n",
        "> Be sure to cite any sources that you draw inspiration from. \n",
        "\n",
        "> You may not directly copy someone else's code - plagiarism detection is very easy. All of the usual academic honestly policies apply. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKMaD0DN6LXO"
      },
      "source": [
        "> * Choose something that interests you.  It makes the lab more fun.\n",
        ">\n",
        "> * Determine your problem type \n",
        ">   * e.g., classification, regression, auto-regression, reinforcement\n",
        ">\n",
        "> * Split to train/validation/test and use each appropriately.\n",
        ">\n",
        "> * Some datasets are very large. You do not have to use ALL of it (i.e. subsample).\n",
        ">   * size is problem dependent, but look to Activies 18-20 for guidance\n",
        ">\n",
        ">\n",
        "> * Develop your approach on a (very?) small subset of data (for speed) and scale up after you finish your empirical design. \n",
        "> \n",
        "> * Look at our Activities and [Towards Data Science](https://towardsdatascience.com/) articles for ideas and inspiration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSn4CcZb7LyW"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4rG1uwiKUSvS"
      },
      "outputs": [],
      "source": [
        "# load your dataset \n",
        "df_spot = pd.read_csv('deezer_spotify.csv')\n",
        "df_meta = pd.read_csv('deezer_metadata.csv')\n",
        "df_tags = pd.read_csv('deezer_lastfm_best_tag.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WwbaWMhJjdH"
      },
      "source": [
        "### Pre-process dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EdahaYaCJl3a"
      },
      "outputs": [],
      "source": [
        "# function to graph data - used in lab 3\n",
        "def plot_val_vs_aro(valence, arousal, colors='b', plt_size=14, dot_size=20):\n",
        "    \"\"\"\n",
        "    Plot a scatterplot of Valance vs Arousal with labels for each corresponding emotion.\n",
        "\n",
        "    Args:\n",
        "        valence (list): list of valance values\n",
        "        arousal (list): list of arousal values\n",
        "        colors (str, optional): matplotlib.pyplot color code. Defaults to 'b' for blue tones.\n",
        "        plt_size (int, optional): plot figure size. Defaults to 14.\n",
        "        dot_size (int, optional): data point size. Defaults to 20.\n",
        "    \"\"\"\n",
        "    title = 'Valence vs. Arousal'\n",
        "    x_label = 'Valence'\n",
        "    y_label = 'Arousal'\n",
        "\n",
        "    plt.figure(figsize=(plt_size,plt_size))\n",
        "    plt.scatter(valence, arousal, s=dot_size, c=colors, alpha=.5)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.xlim(-1.25,1.25)\n",
        "    plt.ylim(-1.25,1.25)   \n",
        "\n",
        "    # draw the unit circle\n",
        "    fig = plt.gcf()\n",
        "    ax = fig.gca()\n",
        "    circle1 = plt.Circle((0, 0), 1.0, color='0.25', fill=False)\n",
        "    ax.add_artist(circle1)\n",
        "\n",
        "    # print emotion labels\n",
        "    plt.text(0.98, 0.35, 'Happy', fontsize=plt_size)\n",
        "    plt.text(0.5, 0.9, 'Excited', fontsize=plt_size)\n",
        "    plt.text(-1.16, 0.35, 'Afraid', fontsize=plt_size)\n",
        "    plt.text(-0.7, 0.9, 'Angry', fontsize=plt_size)\n",
        "    plt.text(-1.13, -0.25, 'Sad', fontsize=plt_size)\n",
        "    plt.text(-0.9, -0.9, 'Depressed', fontsize=plt_size)\n",
        "    plt.text(0.98, -0.25, 'Content', fontsize=plt_size)\n",
        "    plt.text(0.7, -0.9, 'Calm', fontsize=plt_size)\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# function to graph data - used in lab 3\n",
        "def plot_true_vs_pred(true, pred, x_label, y_label, title, colors='b', plt_size=14, dot_size=20) :\n",
        "    \"\"\"\n",
        "    Plot true vs predicted with a regression line of best fit. Can be used for valance OR arousal.\n",
        "\n",
        "    Args:\n",
        "        true (list): True values\n",
        "        pred (list): predicted valaues\n",
        "        x_label (str): label for true values.\n",
        "        y_label (str): label for predicted values.\n",
        "        title (str): title of chart\n",
        "        colors (str, optional): matplotlib.pyplot color code. Defaults to 'b' for blue tones.\n",
        "        plt_size (int, optional): plot figure size. Defaults to 14.\n",
        "        dot_size (int, optional): data point size. Defaults to 20.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(plt_size,plt_size))\n",
        "    plt.scatter(true, pred, s=dot_size, c=colors, alpha=.5)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.title(title)\n",
        "    \n",
        "    # draw the regression line\n",
        "    m, b = np.polyfit(true, pred, 1)\n",
        "    plt.plot(true, m*true + b, color='red', linewidth=2)    \n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize valence and arousal to (-1,1)\n",
        "df_meta['valence'] = MinMaxScaler(feature_range=(-1,1)).fit_transform(np.array(df_meta['valence']).reshape(-1,1))\n",
        "df_meta['arousal'] = MinMaxScaler(feature_range=(-1,1)).fit_transform(np.array(df_meta['arousal']).reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#merge dataframes to create one dataframe with all features and target classes\n",
        "df_feats = pd.merge(df_meta, df_tags)\n",
        "df_feats = pd.merge(df_feats, df_spot)\n",
        "\n",
        "# drop features that are not needed\n",
        "df_feats = df_feats.drop(['MSD_track_id', 'dzr_sng_id', 'MSD_sng_id', 'track_name', 'artist_name'], axis=1)\n",
        "df_spot = df_spot.drop(['MSD_track_id'], axis=1)\n",
        "df_tags = df_tags.drop(['MSD_track_id'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valence</th>\n",
              "      <th>arousal</th>\n",
              "      <th>lastfm_tag</th>\n",
              "      <th>lastfm_tag_rank</th>\n",
              "      <th>sp_acousticness</th>\n",
              "      <th>sp_danceability</th>\n",
              "      <th>sp_duration_ms</th>\n",
              "      <th>sp_energy</th>\n",
              "      <th>sp_instrumentalness</th>\n",
              "      <th>sp_key</th>\n",
              "      <th>sp_liveness</th>\n",
              "      <th>sp_loudness</th>\n",
              "      <th>sp_mode</th>\n",
              "      <th>sp_speechiness</th>\n",
              "      <th>sp_tempo</th>\n",
              "      <th>sp_time_sig</th>\n",
              "      <th>sp_valence</th>\n",
              "      <th>sp_popularity</th>\n",
              "      <th>sp_explicit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.206795</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>Melodic Death Metal</td>\n",
              "      <td>189</td>\n",
              "      <td>0.001620</td>\n",
              "      <td>0.315</td>\n",
              "      <td>412000.0</td>\n",
              "      <td>0.7950</td>\n",
              "      <td>0.196000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0776</td>\n",
              "      <td>-9.645</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0574</td>\n",
              "      <td>138.293</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.413</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.595273</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>black metal</td>\n",
              "      <td>172</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.171</td>\n",
              "      <td>440320.0</td>\n",
              "      <td>0.7980</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0759</td>\n",
              "      <td>-5.548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0622</td>\n",
              "      <td>110.058</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.130</td>\n",
              "      <td>19.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.884786</td>\n",
              "      <td>-0.340580</td>\n",
              "      <td>blues</td>\n",
              "      <td>34</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.579</td>\n",
              "      <td>360640.0</td>\n",
              "      <td>0.0972</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0766</td>\n",
              "      <td>-13.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0477</td>\n",
              "      <td>78.526</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.354</td>\n",
              "      <td>9.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.604136</td>\n",
              "      <td>0.177536</td>\n",
              "      <td>dance</td>\n",
              "      <td>9</td>\n",
              "      <td>0.008590</td>\n",
              "      <td>0.710</td>\n",
              "      <td>171747.0</td>\n",
              "      <td>0.9630</td>\n",
              "      <td>0.013300</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.2180</td>\n",
              "      <td>-4.787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>129.965</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.968</td>\n",
              "      <td>51.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.843427</td>\n",
              "      <td>0.344203</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>21</td>\n",
              "      <td>0.082700</td>\n",
              "      <td>0.491</td>\n",
              "      <td>148400.0</td>\n",
              "      <td>0.7110</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.2460</td>\n",
              "      <td>-6.463</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0330</td>\n",
              "      <td>119.001</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.545</td>\n",
              "      <td>22.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18639</th>\n",
              "      <td>-0.680945</td>\n",
              "      <td>0.657609</td>\n",
              "      <td>Melodic Death Metal</td>\n",
              "      <td>189</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.174</td>\n",
              "      <td>209507.0</td>\n",
              "      <td>0.9880</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7200</td>\n",
              "      <td>-3.420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>126.399</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.103</td>\n",
              "      <td>27.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18640</th>\n",
              "      <td>-0.497784</td>\n",
              "      <td>0.170290</td>\n",
              "      <td>pop</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.693</td>\n",
              "      <td>513520.0</td>\n",
              "      <td>0.7310</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0737</td>\n",
              "      <td>-6.666</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0483</td>\n",
              "      <td>130.033</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.602</td>\n",
              "      <td>22.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18641</th>\n",
              "      <td>0.800591</td>\n",
              "      <td>0.382246</td>\n",
              "      <td>60s</td>\n",
              "      <td>56</td>\n",
              "      <td>0.133000</td>\n",
              "      <td>0.533</td>\n",
              "      <td>156093.0</td>\n",
              "      <td>0.8330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>-7.706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0334</td>\n",
              "      <td>128.399</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.581</td>\n",
              "      <td>23.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18642</th>\n",
              "      <td>-0.266765</td>\n",
              "      <td>-0.162319</td>\n",
              "      <td>classic rock</td>\n",
              "      <td>19</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.472</td>\n",
              "      <td>382297.0</td>\n",
              "      <td>0.3660</td>\n",
              "      <td>0.308000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0837</td>\n",
              "      <td>-12.595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0286</td>\n",
              "      <td>127.167</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.171</td>\n",
              "      <td>75.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18643</th>\n",
              "      <td>0.364845</td>\n",
              "      <td>-0.445652</td>\n",
              "      <td>classic rock</td>\n",
              "      <td>19</td>\n",
              "      <td>0.024100</td>\n",
              "      <td>0.469</td>\n",
              "      <td>382834.0</td>\n",
              "      <td>0.5370</td>\n",
              "      <td>0.002010</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.2690</td>\n",
              "      <td>-10.421</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>124.193</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.783</td>\n",
              "      <td>74.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18644 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        valence   arousal           lastfm_tag  lastfm_tag_rank  \\\n",
              "0     -0.206795  0.041667  Melodic Death Metal              189   \n",
              "1     -0.595273  0.521739          black metal              172   \n",
              "2     -0.884786 -0.340580                blues               34   \n",
              "3      0.604136  0.177536                dance                9   \n",
              "4      0.843427  0.344203           indie rock               21   \n",
              "...         ...       ...                  ...              ...   \n",
              "18639 -0.680945  0.657609  Melodic Death Metal              189   \n",
              "18640 -0.497784  0.170290                  pop                2   \n",
              "18641  0.800591  0.382246                  60s               56   \n",
              "18642 -0.266765 -0.162319         classic rock               19   \n",
              "18643  0.364845 -0.445652         classic rock               19   \n",
              "\n",
              "       sp_acousticness  sp_danceability  sp_duration_ms  sp_energy  \\\n",
              "0             0.001620            0.315        412000.0     0.7950   \n",
              "1             0.000010            0.171        440320.0     0.7980   \n",
              "2             0.924000            0.579        360640.0     0.0972   \n",
              "3             0.008590            0.710        171747.0     0.9630   \n",
              "4             0.082700            0.491        148400.0     0.7110   \n",
              "...                ...              ...             ...        ...   \n",
              "18639         0.000090            0.174        209507.0     0.9880   \n",
              "18640         0.000019            0.693        513520.0     0.7310   \n",
              "18641         0.133000            0.533        156093.0     0.8330   \n",
              "18642         0.150000            0.472        382297.0     0.3660   \n",
              "18643         0.024100            0.469        382834.0     0.5370   \n",
              "\n",
              "       sp_instrumentalness  sp_key  sp_liveness  sp_loudness  sp_mode  \\\n",
              "0                 0.196000     6.0       0.0776       -9.645      0.0   \n",
              "1                 0.029500    11.0       0.0759       -5.548      0.0   \n",
              "2                 0.001050    10.0       0.0766      -13.925      1.0   \n",
              "3                 0.013300    11.0       0.2180       -4.787      0.0   \n",
              "4                 0.000064    10.0       0.2460       -6.463      1.0   \n",
              "...                    ...     ...          ...          ...      ...   \n",
              "18639             0.898000     0.0       0.7200       -3.420      0.0   \n",
              "18640             0.020700    11.0       0.0737       -6.666      1.0   \n",
              "18641             0.000000     0.0       0.2280       -7.706      1.0   \n",
              "18642             0.308000    11.0       0.0837      -12.595      0.0   \n",
              "18643             0.002010     9.0       0.2690      -10.421      1.0   \n",
              "\n",
              "       sp_speechiness  sp_tempo  sp_time_sig  sp_valence  sp_popularity  \\\n",
              "0              0.0574   138.293          3.0       0.413           18.0   \n",
              "1              0.0622   110.058          4.0       0.130           19.0   \n",
              "2              0.0477    78.526          4.0       0.354            9.0   \n",
              "3              0.0277   129.965          4.0       0.968           51.0   \n",
              "4              0.0330   119.001          4.0       0.545           22.0   \n",
              "...               ...       ...          ...         ...            ...   \n",
              "18639          0.1070   126.399          4.0       0.103           27.0   \n",
              "18640          0.0483   130.033          4.0       0.602           22.0   \n",
              "18641          0.0334   128.399          4.0       0.581           23.0   \n",
              "18642          0.0286   127.167          4.0       0.171           75.0   \n",
              "18643          0.1520   124.193          1.0       0.783           74.0   \n",
              "\n",
              "      sp_explicit  \n",
              "0           False  \n",
              "1           False  \n",
              "2           False  \n",
              "3           False  \n",
              "4           False  \n",
              "...           ...  \n",
              "18639        True  \n",
              "18640       False  \n",
              "18641       False  \n",
              "18642       False  \n",
              "18643       False  \n",
              "\n",
              "[18644 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sp_acousticness</th>\n",
              "      <th>sp_danceability</th>\n",
              "      <th>sp_duration_ms</th>\n",
              "      <th>sp_energy</th>\n",
              "      <th>sp_instrumentalness</th>\n",
              "      <th>sp_key</th>\n",
              "      <th>sp_liveness</th>\n",
              "      <th>sp_loudness</th>\n",
              "      <th>sp_mode</th>\n",
              "      <th>sp_speechiness</th>\n",
              "      <th>sp_tempo</th>\n",
              "      <th>sp_time_sig</th>\n",
              "      <th>sp_valence</th>\n",
              "      <th>sp_popularity</th>\n",
              "      <th>sp_explicit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.131000</td>\n",
              "      <td>0.460</td>\n",
              "      <td>278267.0</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.041700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0527</td>\n",
              "      <td>-9.233</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0445</td>\n",
              "      <td>138.002</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.532</td>\n",
              "      <td>53.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.394000</td>\n",
              "      <td>0.520</td>\n",
              "      <td>299613.0</td>\n",
              "      <td>0.253</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1090</td>\n",
              "      <td>-12.407</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0344</td>\n",
              "      <td>139.555</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.219</td>\n",
              "      <td>60.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.056200</td>\n",
              "      <td>0.909</td>\n",
              "      <td>219840.0</td>\n",
              "      <td>0.740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0593</td>\n",
              "      <td>-2.361</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2600</td>\n",
              "      <td>97.855</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.802</td>\n",
              "      <td>54.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.905000</td>\n",
              "      <td>0.701</td>\n",
              "      <td>223613.0</td>\n",
              "      <td>0.202</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>-12.480</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0609</td>\n",
              "      <td>85.389</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.477</td>\n",
              "      <td>53.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.818000</td>\n",
              "      <td>0.499</td>\n",
              "      <td>298237.0</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.1430</td>\n",
              "      <td>-12.145</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0276</td>\n",
              "      <td>72.139</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.234</td>\n",
              "      <td>48.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18639</th>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.174</td>\n",
              "      <td>209507.0</td>\n",
              "      <td>0.988</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7200</td>\n",
              "      <td>-3.420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>126.399</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.103</td>\n",
              "      <td>27.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18640</th>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.693</td>\n",
              "      <td>513520.0</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0737</td>\n",
              "      <td>-6.666</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0483</td>\n",
              "      <td>130.033</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.602</td>\n",
              "      <td>22.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18641</th>\n",
              "      <td>0.133000</td>\n",
              "      <td>0.533</td>\n",
              "      <td>156093.0</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>-7.706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0334</td>\n",
              "      <td>128.399</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.581</td>\n",
              "      <td>23.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18642</th>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.472</td>\n",
              "      <td>382297.0</td>\n",
              "      <td>0.366</td>\n",
              "      <td>0.308000</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0837</td>\n",
              "      <td>-12.595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0286</td>\n",
              "      <td>127.167</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.171</td>\n",
              "      <td>75.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18643</th>\n",
              "      <td>0.024100</td>\n",
              "      <td>0.469</td>\n",
              "      <td>382834.0</td>\n",
              "      <td>0.537</td>\n",
              "      <td>0.002010</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.2690</td>\n",
              "      <td>-10.421</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>124.193</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.783</td>\n",
              "      <td>74.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18644 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sp_acousticness  sp_danceability  sp_duration_ms  sp_energy  \\\n",
              "0             0.131000            0.460        278267.0      0.772   \n",
              "1             0.394000            0.520        299613.0      0.253   \n",
              "2             0.056200            0.909        219840.0      0.740   \n",
              "3             0.905000            0.701        223613.0      0.202   \n",
              "4             0.818000            0.499        298237.0      0.201   \n",
              "...                ...              ...             ...        ...   \n",
              "18639         0.000090            0.174        209507.0      0.988   \n",
              "18640         0.000019            0.693        513520.0      0.731   \n",
              "18641         0.133000            0.533        156093.0      0.833   \n",
              "18642         0.150000            0.472        382297.0      0.366   \n",
              "18643         0.024100            0.469        382834.0      0.537   \n",
              "\n",
              "       sp_instrumentalness  sp_key  sp_liveness  sp_loudness  sp_mode  \\\n",
              "0                 0.041700     0.0       0.0527       -9.233      1.0   \n",
              "1                 0.000131     0.0       0.1090      -12.407      1.0   \n",
              "2                 0.000000     1.0       0.0593       -2.361      1.0   \n",
              "3                 0.000157     1.0       0.1070      -12.480      1.0   \n",
              "4                 0.000001    11.0       0.1430      -12.145      1.0   \n",
              "...                    ...     ...          ...          ...      ...   \n",
              "18639             0.898000     0.0       0.7200       -3.420      0.0   \n",
              "18640             0.020700    11.0       0.0737       -6.666      1.0   \n",
              "18641             0.000000     0.0       0.2280       -7.706      1.0   \n",
              "18642             0.308000    11.0       0.0837      -12.595      0.0   \n",
              "18643             0.002010     9.0       0.2690      -10.421      1.0   \n",
              "\n",
              "       sp_speechiness  sp_tempo  sp_time_sig  sp_valence  sp_popularity  \\\n",
              "0              0.0445   138.002          4.0       0.532           53.0   \n",
              "1              0.0344   139.555          3.0       0.219           60.0   \n",
              "2              0.2600    97.855          4.0       0.802           54.0   \n",
              "3              0.0609    85.389          4.0       0.477           53.0   \n",
              "4              0.0276    72.139          4.0       0.234           48.0   \n",
              "...               ...       ...          ...         ...            ...   \n",
              "18639          0.1070   126.399          4.0       0.103           27.0   \n",
              "18640          0.0483   130.033          4.0       0.602           22.0   \n",
              "18641          0.0334   128.399          4.0       0.581           23.0   \n",
              "18642          0.0286   127.167          4.0       0.171           75.0   \n",
              "18643          0.1520   124.193          1.0       0.783           74.0   \n",
              "\n",
              "      sp_explicit  \n",
              "0           False  \n",
              "1           False  \n",
              "2            True  \n",
              "3           False  \n",
              "4           False  \n",
              "...           ...  \n",
              "18639        True  \n",
              "18640       False  \n",
              "18641       False  \n",
              "18642       False  \n",
              "18643       False  \n",
              "\n",
              "[18644 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lastfm_tag</th>\n",
              "      <th>lastfm_tag_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18639</th>\n",
              "      <td>the goodbye song</td>\n",
              "      <td>498810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18640</th>\n",
              "      <td>the word barren</td>\n",
              "      <td>500920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18641</th>\n",
              "      <td>the word sod</td>\n",
              "      <td>501681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18642</th>\n",
              "      <td>tori amosesque</td>\n",
              "      <td>506032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18643</th>\n",
              "      <td>yec</td>\n",
              "      <td>520008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18644 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             lastfm_tag  lastfm_tag_rank\n",
              "0                  none                0\n",
              "1                  none                0\n",
              "2                  none                0\n",
              "3                  none                0\n",
              "4                  none                0\n",
              "...                 ...              ...\n",
              "18639  the goodbye song           498810\n",
              "18640   the word barren           500920\n",
              "18641      the word sod           501681\n",
              "18642    tori amosesque           506032\n",
              "18643               yec           520008\n",
              "\n",
              "[18644 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df_feats)\n",
        "display(df_spot)\n",
        "display(df_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#clean up data frames to get ready for training and Kmeans clustering\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "df_feats = pd.DataFrame(imp.fit_transform(df_feats), columns=df_feats.columns)\n",
        "df_spot = pd.DataFrame(imp.fit_transform(df_spot), columns=df_spot.columns)\n",
        "\n",
        "#encode categorical data\n",
        "ohe = OneHotEncoder()\n",
        "le = LabelEncoder()\n",
        "\n",
        "df_feats['sp_explicit'] = le.fit_transform(df_feats['sp_explicit'])\n",
        "df_feats['lastfm_tag'] = ohe.fit_transform(df_feats['lastfm_tag'])\n",
        "df_spot['sp_explicit'] = le.fit_transform(df_spot['sp_explicit'])\n",
        "df_tags['lastfm_tag'] = ohe.fit_transform(df_tags['lastfm_tag'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPs0aPJy0Gk6"
      },
      "source": [
        "***\n",
        "# Workspace\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## view our valence-arousal space for our examples\n",
        "plot_val_vs_aro(df_feats['valence'], df_feats['arousal'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def elbow_method(feats):\n",
        "# Elbow method to determine optimal number of clusters\n",
        "    dist_acoustic = []\n",
        "    for i in range(1, 11):\n",
        "        kmeans = KMeans(n_clusters=i, random_state=1)\n",
        "        kmeans.fit(feats)\n",
        "        dist_acoustic.append(kmeans.inertia_)\n",
        "    plt.plot(range(1, 11), dist_acoustic)\n",
        "    plt.xlabel('Number of clusters')\n",
        "    plt.ylabel('distortion')\n",
        "    plt.title('Elbow Method - df_acoustic')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "# Transform the features using QuantileTransformer\n",
        "qt = QuantileTransformer(random_state=1)\n",
        "spot = qt.fit_transform(df_spot.values)\n",
        "tags = qt.fit_transform(df_tags.values)\n",
        "\n",
        "elbow_method(spot)\n",
        "elbow_method(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_km_spot = KMeans(n_clusters=5, random_state=1).fit_predict(spot)\n",
        "y_km_tags = KMeans(n_clusters=5, random_state=1).fit_predict(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_clusters(n, y_km):\n",
        "    # print number of examples in each cluster for each feature subset\n",
        "    clust_name = 'spot'\n",
        "    for i in range(n):\n",
        "        print(f'{clust_name} cluster {i+1}: {np.count_nonzero(y_km == i)} examples')\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_clusters(5, y_km_spot)\n",
        "print_clusters(5, y_km_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feats['spot_cluster'] = y_km_spot\n",
        "df_feats['tags_cluster'] = y_km_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split data into training and testing sets\n",
        "X = df_feats.drop(['valence', 'arousal'], axis=1)\n",
        "y_valence = df_feats['valence']\n",
        "y_arousal = df_feats['arousal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "704/704 [==============================] - 109s 154ms/step - loss: 2.2130 - accuracy: 0.1644 - val_loss: 2.3222 - val_accuracy: 0.1474 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "704/704 [==============================] - 107s 152ms/step - loss: 2.0125 - accuracy: 0.2673 - val_loss: 1.8909 - val_accuracy: 0.3336 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "704/704 [==============================] - 137s 195ms/step - loss: 1.8984 - accuracy: 0.3202 - val_loss: 1.7394 - val_accuracy: 0.3824 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "704/704 [==============================] - 96s 136ms/step - loss: 1.7860 - accuracy: 0.3597 - val_loss: 1.6648 - val_accuracy: 0.4096 - lr: 0.0090\n",
            "Epoch 5/10\n",
            "704/704 [==============================] - 91s 129ms/step - loss: 1.7036 - accuracy: 0.3866 - val_loss: 1.5933 - val_accuracy: 0.4364 - lr: 0.0090\n",
            "Epoch 6/10\n",
            "704/704 [==============================] - 102s 144ms/step - loss: 1.6351 - accuracy: 0.4098 - val_loss: 1.7220 - val_accuracy: 0.3672 - lr: 0.0090\n",
            "Epoch 7/10\n",
            "294/704 [===========>..................] - ETA: 59s - loss: 1.5888 - accuracy: 0.4222"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\Fordr\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# split data into training and testing sets for valence and arousal\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_valence, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.25, random_state=42)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y_arousal, test_size=0.2, random_state=42)\n",
        "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train2, y_train2, test_size=.25, random_state=42)\n",
        "\n",
        "\n",
        "# scale data\n",
        "qt = QuantileTransformer()\n",
        "X_train = qt.fit_transform(X_train)\n",
        "X_test = qt.transform(X_test)\n",
        "X_val = qt.transform(X_val)\n",
        "\n",
        "# Build the convolutional neural network\n",
        "input_layer = keras.layers.Input(shape=(X_train.shape[1],))\n",
        "x = keras.layers.Dense(32, activation='tanh')(input_layer)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "# Skip connection\n",
        "skip = x  # Save the output of this layer to connect to the final output\n",
        "\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Dense(128, activation='tanh')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Dense(32, activation='relu')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "# Add the skip connection\n",
        "x = keras.layers.Add()([x, skip])\n",
        "\n",
        "output_layer = keras.layers.Dense(1, activation='tanh')(x)\n",
        "\n",
        "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# make a decaying learning rate\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 2:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.05)\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=.01)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# train neural network\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_val, y_val), callbacks=[callback])\n",
        "model.evaluate(X_test, y_test)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "preds = preds.reshape(-1)\n",
        "# get pearson correlation\n",
        "corr, _ = pearsonr(preds, y_test)\n",
        "print('Pearsons correlation: %.3f' % corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ35u3SZ5_BO"
      },
      "source": [
        "##### Protips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlXeHSA5Ct88"
      },
      "source": [
        "Organization:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv552V2b6EV5"
      },
      "source": [
        "> **Make sure your work is organized and \"readable\" to someone else:**\n",
        "> * Organize your work using different text and code blocks\n",
        "> * Use section subheaders (i.e. `##`, `###`, `####`, etc.) to format your text blocks\n",
        "> * Wrap your code in functions for reuse in report\n",
        "> * Document your work: either with code comments or text blocks (ideally both)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPWHv6dCCrjk"
      },
      "source": [
        "Model design:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9mPtCl7CqaX"
      },
      "source": [
        "\n",
        "> Different data problems require different architectures. For example,\n",
        ">  * images/videos use CNNs\n",
        ">  * sequential/temporal data uses RNNs\n",
        ">  * game/action data uses DQNs\n",
        ">\n",
        "> Different data problems require different network sizes\n",
        "> * Use at least 2 hidden layers (for deep-learning)\n",
        ">    * *how many to use?* is data/problem dependent question\n",
        ">\n",
        "> Research your problem domain and make justifiable decisions. **You are expected to explain what you chose and why in your report.**\n",
        "\n",
        "> If appropriate, consider an empirical comparison to a baseline/simple model\n",
        "> * e.g., start with a simple `sklearn` classification/regression model and then move on to a `Tensorflow` Deep Learning model\n",
        "> * This allows you to empiracally show how much better deep learning performs over more conventional models\n",
        "> * note: this doesn't make sense for some data (e.g., images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO9-GGiNCnGY"
      },
      "source": [
        "Ethics:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dKGNMbHCyDD"
      },
      "source": [
        "> * **DO** use web articles and APIs for ideas, tips, and guidance\n",
        "> * **DO** read code examples from sources including TowardsDataScience, Stackoverflow, github \n",
        "> * **DO** adapt ideas from your \"inspired by\" sources\n",
        "> * **DO** cite any articles you used for inspiration or for technical help\n",
        ">\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJMuw5CBDqLh"
      },
      "source": [
        "> * **DON'T** need to cite common APIs (e.g., tensorflow, pandas)\n",
        "> * **DON'T** just blindly recreate some web tutorial\n",
        "> * **DON'T** cut and paste from the web\n",
        "> * **DON'T** plagiarize (rather you should adapt and cite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG5NCz1b0Jie"
      },
      "source": [
        "## Experiment(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw7nSkZGIwAm"
      },
      "source": [
        "Design and run experiments to demonstrate the efficacy of your solution. \n",
        "\n",
        "Wrap your code in functions so that you can reuse them in your report.\n",
        "\n",
        "For code that takes a long time to run, consider storing results in variables so that you can reuse values without rerunning full experiments. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svP2m5j-x0Z7"
      },
      "source": [
        "***\n",
        "# Report\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QUbZ1BC3U8u"
      },
      "source": [
        "### Expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSKkzOVryvTX"
      },
      "source": [
        "Write a research \"paper\" that summarizes your work.\n",
        "\n",
        "Your report should include the following sections.\n",
        "\n",
        "1. [Introduction](https://libguides.usc.edu/writingguide/introduction)\n",
        "2. Dataset and Pre-processing\n",
        "3. [Methods](https://libguides.usc.edu/writingguide/methodology) (Experiment)\n",
        "4. [Results and Analysis](https://libguides.usc.edu/writingguide/results)\n",
        "5. [Discussion](https://libguides.usc.edu/writingguide/discussion) and [Conclusion](https://libguides.usc.edu/writingguide/conclusion)\n",
        "6. [References](https://libguides.usc.edu/writingguide/citingsources)\n",
        "\n",
        "This should be a thorough, long and thoughtful paper. It should be able to stand alone and give a clear understanding of your process without needing to refer to code above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jTBmap73RIR"
      },
      "source": [
        "##### Protips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b48jOdrRyvRU"
      },
      "source": [
        "> * Explain your problem statement, your data, your experimental design decisions, your results, and your analysis.\n",
        ">   * assume an audience that is completely unfamiliar with your problem, but understands deep-learning.  \n",
        ">\n",
        "> * Use subheaders for your sections.\n",
        ">\n",
        "> * Some sections will be shorter (e.g. Intro) while others will be much longer (e.g. Methods or Results).\n",
        ">\n",
        "> * Justify your design choices.\n",
        ">   * this could be shown empirically, drawn from external (cited) sourches, or given as explanations of your intuitions about the problem domain\n",
        ">\n",
        "> * Integrate your programmatic results (results, graphs, tables, etc.) within your report to support your prose. \n",
        ">\n",
        "> * *Results* section explains the \"what\" of your findings; *Discussion* explains the \"why\".\n",
        ">\n",
        "> * You do not need to \"formally\" (e.g., APA) cite your references.\n",
        ">    * rather, provide a title, author (if given), and URL\n",
        ">    * e.g., Dumane, G. [Introduction to Convolutional Neural Network (CNN) using Tensorflow](https://towardsdatascience.com/introduction-to-convolutional-neural-network-cnn-de73f69c5b83)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRHnTMBc-FMs"
      },
      "source": [
        "### <MY TITLE HERE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn9l0JqG-Iho"
      },
      "source": [
        "## < MY AWESOME REPORT TITLE HERE INSTEAD OF THIS SHITTY PLACEHOLDER TEXT> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyFV97eT-RbB"
      },
      "source": [
        "*your report starts here* "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3SgoQShs6JVF",
        "iJ35u3SZ5_BO",
        "3jTBmap73RIR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
